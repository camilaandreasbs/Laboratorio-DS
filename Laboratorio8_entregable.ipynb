{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio8_entregable.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "038fcdf2-d87a-4a74-89c6-f5afff22afb6",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Tabla de Contenidos",
      "title_sidebar": "Contenidos",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "241.867px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camilaandreasbs/Laboratorio-DS/blob/master/Laboratorio8_entregable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZ1dFPHzAHl"
      },
      "source": [
        "<h1><center>Laboratorio 8: 驴Superh茅roe o Villano? Ω</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci贸n Cient铆fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla\n",
        "- Auxiliar: Ignacio Meza D.\n",
        "- Ayudante: Constanza Pe帽a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser谩n revisados\n",
        "\n",
        "- Nombre de alumno 1: Camila Bergasa\n",
        "- Nombre de alumno 2: Sebasti谩n Garc铆a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### Indice \n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci贸n del laboratorio](#Descripci贸n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "# Temas a tratar\n",
        "\n",
        "- Exploraci贸n del dataset y los resultados a trav茅s de visualizaciones interactivas usando `plotly`.\n",
        "- Introducci贸n a procesamiento del lenguaje natural.\n",
        "- Clasificaci贸n en `scikit-learn`\n",
        "- Uso de pipelines.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- Fecha de entrega: 26/11/2021\n",
        "- **Grupos de 2 personas**\n",
        "- **Ausentes** deber谩n realizar la actividad solos. \n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser谩n respondidos por este medio.\n",
        "- Prohibidas las copias. \n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
        "- Obtener caracteristicas desde texto.\n",
        "- Visualizar el funcionamiento de clasificadores.\n",
        "- Realizar una GridSearch sobre un conjunto de clasificadores.\n",
        "\n",
        "El laboratorio deber谩 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m谩ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m谩s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhISwri4zAHy"
      },
      "source": [
        "#Importamos librerias utiles "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyc33dKdzAHy",
        "outputId": "bba3abbf-4c2e-4fcc-df33-1daa70d8e591"
      },
      "source": [
        "# Librer铆a Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif, mutual_info_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifaci贸n\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Metricas de evaluaci贸n\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librer铆a para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librer铆a para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (4.4.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.4.0-py2.py3-none-any.whl (25.3 MB)\n",
            "\u001b[K     || 25.3 MB 63.9 MB/s \n",
            "\u001b[?25hCollecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Installing collected packages: tenacity, plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-5.4.0 tenacity-8.0.1\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     || 86 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.5.tar.gz (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 21.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82709 sha256=6613caeed7334744f729700a3ac5d3397f451b33e89869f330df5cfd7d5f7349\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.5-py3-none-any.whl size=52603 sha256=073786c1555d4a69375da0f1d95dab1c953f31457cefbff4a527025933544691\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/e9/33/04db1436df0757c42fda8ea6796d7a8586e23c85fac355f476\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.5 umap-learn-0.5.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpOTbQcxbSiy"
      },
      "source": [
        "# 1. 驴Quien es Bat Cow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q93vbNS25bM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmZfFpxTTYX"
      },
      "source": [
        "En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineaci贸n (h茅roe o villano) del personaje de ficci贸n Bat-Cow. \n",
        "\n",
        "El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero com煤n caracter铆stica de los personajes malvados. \n",
        "Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n",
        "\n",
        "Sin embargo, ambos concuerdan que es dif铆cil estimar la alineaci贸n solo usando los atributos f铆sicos, por lo que creen el an谩lisis debe ser complementado a煤n m谩s antes de comunicarle los resultados a su estudiantado. Buscando m谩s informaci贸n, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineaci贸n: la historia personal de cada superh茅roe o villano.\n",
        "\n",
        "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineaci贸n de cada personaje basado en su historia personal.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servir谩 para entrenar un modelo de clasificaci贸n, mientras que el segundo es un dataset con personajes de ficci贸n no etiquetados a predecir (s铆, aqu铆 est谩 la misteriosa Batcow).\n",
        "\n",
        "Para comenzar cargue los dataset se帽alados y visualice a trav茅s de un head los atributos que poseen cada uno de los dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqq-s010Iwl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ff13a5-40b8-4e07-d898-3db9e39ff9bd"
      },
      "source": [
        "# Si usted est谩 utilizando Colabolatory le puede ser 煤til este c贸digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/LaboratorioDS/Lab8/df_comics.csv'\n",
        "    path2 = '/content/drive/MyDrive/LaboratorioDS/Lab8/comics_no_labels.csv'\n",
        "except: \n",
        "    print('Ignorando conexi贸n drive-colab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bED3w3tDbSCf"
      },
      "source": [
        "df_comics = pd.read_csv('/content/drive/MyDrive/LaboratorioDS/Lab8/df_comics.csv')\n",
        "\n",
        "df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7j0vadJie9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ad1e15-c2ca-44ad-c01b-8e9aee33698b"
      },
      "source": [
        "# queda a labor de su equipo hacer el an谩lisis exploratorio\n",
        "df_comics.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'name', 'real_name', 'full_name', 'overall_score',\n",
              "       'history_text', 'powers_text', 'intelligence_score', 'strength_score',\n",
              "       'speed_score', 'durability_score', 'power_score', 'combat_score',\n",
              "       'superpowers', 'alter_egos', 'aliases', 'place_of_birth',\n",
              "       'first_appearance', 'creator', 'alignment', 'occupation', 'base',\n",
              "       'teams', 'relatives', 'gender', 'type_race', 'height', 'weight',\n",
              "       'eye_color', 'hair_color', 'skin_color', 'img', 'has_electrokinesis',\n",
              "       'has_energy_constructs', 'has_mind_control_resistance',\n",
              "       'has_matter_manipulation', 'has_telepathy_resistance',\n",
              "       'has_mind_control', 'has_enhanced_hearing', 'has_dimensional_travel',\n",
              "       'has_element_control', 'has_size_changing', 'has_fire_resistance',\n",
              "       'has_fire_control', 'has_dexterity', 'has_reality_warping',\n",
              "       'has_illusions', 'has_energy_beams', 'has_peak_human_condition',\n",
              "       'has_shapeshifting', 'has_heat_resistance', 'has_jump',\n",
              "       'has_self-sustenance', 'has_energy_absorption', 'has_cold_resistance',\n",
              "       'has_magic', 'has_telekinesis', 'has_toxin_and_disease_resistance',\n",
              "       'has_telepathy', 'has_regeneration', 'has_immortality',\n",
              "       'has_teleportation', 'has_force_fields', 'has_energy_manipulation',\n",
              "       'has_endurance', 'has_longevity', 'has_weapon-based_powers',\n",
              "       'has_energy_blasts', 'has_enhanced_senses', 'has_invulnerability',\n",
              "       'has_stealth', 'has_marksmanship', 'has_flight',\n",
              "       'has_accelerated_healing', 'has_weapons_master', 'has_intelligence',\n",
              "       'has_reflexes', 'has_super_speed', 'has_durability', 'has_stamina',\n",
              "       'has_agility', 'has_super_strength'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "Ig1b9wb7bIZK",
        "outputId": "7ecfc6fc-a5be-4755-9628-4dde72ff034c"
      },
      "source": [
        "df_comics[\"alignment\"].value_counts().to_frame()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alignment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         alignment\n",
              "Good           743\n",
              "Bad            429\n",
              "Neutral        113"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Z6zVWB2A01",
        "outputId": "c14ebf4b-ac2b-4063-9c36-36811272490f"
      },
      "source": [
        "df_comics.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1285, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVtcbpuzCAb2"
      },
      "source": [
        "Vamos a eliminar los neutrales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAwq392B-oo"
      },
      "source": [
        "df_comics = df_comics.drop(df_comics[df_comics[\"alignment\"]==\"Neutral\"].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "yKC4ufXW2Mme",
        "outputId": "3ea39476-2352-4476-854c-af8a9d4a9bcf"
      },
      "source": [
        "df_comics[\"alignment\"].value_counts().to_frame()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alignment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      alignment\n",
              "Good        743\n",
              "Bad         429"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTwRZsIpCl_R",
        "outputId": "4334e373-91d1-4a53-d2be-291f6e366e14"
      },
      "source": [
        "df_comics.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1172, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onAwbWibt1YT",
        "outputId": "45cdaf7d-7e34-41c8-928c-a69aab93366a"
      },
      "source": [
        "df_comics.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0              0\n",
              "name                    0\n",
              "real_name             111\n",
              "full_name             347\n",
              "overall_score           0\n",
              "                     ... \n",
              "has_super_speed        56\n",
              "has_durability         56\n",
              "has_stamina            56\n",
              "has_agility            56\n",
              "has_super_strength     56\n",
              "Length: 82, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4tFPrFA4_O5"
      },
      "source": [
        "## 1.1 Obtenci贸n de Features y Bag of Words\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4NF0_V5XZ-"
      },
      "source": [
        "Primero que todo, deben obtener un vector de caracter铆sticas del atributo `history_text`, utilizando `bag of words`. En este atributo se presenta una breve descripci贸n de la historia de cada uno de los personajes de ficci贸n presentes en el dataset. \n",
        "\n",
        "Pero... antes de empezar, 驴Que es `bag of words`?...\n",
        "\n",
        "`bag of words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representaci贸n vectorial (vector de caracter铆sticas en nuestro cas) para cada documento a trav茅s del conteo de las palabras que contienen. \n",
        "\n",
        "La siguiente figura muestra un ejemplo de `bag of words` en acci贸n:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n",
        "</p>\n",
        "\n",
        "Como pueden ver, el modelo de `bag of words` no resulta tan complicado, 驴pero c贸mo lo aplicamos en python?. \n",
        "\n",
        "Como podr谩n darse cuenta del ejemplo anterior, para facilitar el conteo ser谩 necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un car谩cter. Este proceso es conocido como **tokenizaci贸n** y lo podemos realizar de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1dnSw9pie-A",
        "outputId": "128b2662-6611-40d7-c999-5d71acbc3777"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "             'the rock is the best actor in the world']\n",
        "\n",
        "\n",
        "docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n",
        "docs_tokenizados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvssYZwcie-A"
      },
      "source": [
        "Podemos mejorar un poco m谩s el proceso de tokenizaci贸n agregando \n",
        "\n",
        "- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n",
        "- Eliminaci贸n de Stopwords: Eliminaci贸n de palabras muy frecuentes que entorpecen la clasificaci贸n (por ejemplo, el, la los, la, etc...)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql0z_d65ie-B",
        "outputId": "7254fac3-e676-40d2-fe0e-6fc66a789faf"
      },
      "source": [
        "# Definimos algunas stopword que queremos que sean eliminadas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('spanish')\n",
        "\n",
        "# Definimos un tokenizador con Stemming\n",
        "class StemmerTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]\n",
        "\n",
        "# Inicializamos tokenizador\n",
        "tokenizador = StemmerTokenizer()\n",
        "\n",
        "# Creamos algunos documentos\n",
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "        'the rock is the best actor in the world',\n",
        "        'New York is a beautiful city']\n",
        "\n",
        "# Obtenemos el token del primer documento\n",
        "[tokenizador(doc) for doc in docs]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
              " ['new', 'york', 'is', 'beauti', 'citi']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jQ11pb2ie-B",
        "outputId": "33d381f5-414f-4ed9-c40e-dae879984b46"
      },
      "source": [
        "# Comparaci贸n con el caso anterior\n",
        "docs_tokenizados = [word_tokenize(doc) for doc in docs]\n",
        "docs_tokenizados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
              " ['New', 'York', 'is', 'a', 'beautiful', 'city']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ONqF-3ie-B"
      },
      "source": [
        "#### Al Estilo Scikit\n",
        "\n",
        "Scikit implementa `bag of words` a trav茅s de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenizaci贸n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "b163A48Qie-B",
        "outputId": "724f0084-fa4c-44ae-f8ff-7fabe10238e3"
      },
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer())\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>actor</th>\n",
              "      <th>beauti</th>\n",
              "      <th>best</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>in</th>\n",
              "      <th>is</th>\n",
              "      <th>like</th>\n",
              "      <th>new</th>\n",
              "      <th>rock</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>the</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   &  actor  beauti  best  citi  good  ...  rock  roll  teacher  the  world  york\n",
              "0  1      0       0     0     0     1  ...     2     1        1    1      0     0\n",
              "1  0      1       0     1     0     0  ...     1     0        0    3      1     0\n",
              "2  0      0       1     0     1     0  ...     0     0        0    0      0     1\n",
              "\n",
              "[3 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vjQxrfGie-C"
      },
      "source": [
        "Una de las cosas m谩s interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados. \n",
        "\n",
        "Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relaci贸n: `Nueva` `York`.\n",
        "Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como tambi茅n `Nueva York` como un token independiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "ZzKzu_ybie-C",
        "outputId": "3dbb4ab7-6772-415b-ecba-92c7a8c824f2"
      },
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>&amp; roll</th>\n",
              "      <th>actor</th>\n",
              "      <th>actor in</th>\n",
              "      <th>beauti</th>\n",
              "      <th>beauti citi</th>\n",
              "      <th>best</th>\n",
              "      <th>best actor</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>good rock</th>\n",
              "      <th>in</th>\n",
              "      <th>in the</th>\n",
              "      <th>is</th>\n",
              "      <th>is beauti</th>\n",
              "      <th>is the</th>\n",
              "      <th>like</th>\n",
              "      <th>like good</th>\n",
              "      <th>new</th>\n",
              "      <th>new york</th>\n",
              "      <th>rock</th>\n",
              "      <th>rock &amp;</th>\n",
              "      <th>rock is</th>\n",
              "      <th>rock like</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>teacher rock</th>\n",
              "      <th>the</th>\n",
              "      <th>the best</th>\n",
              "      <th>the rock</th>\n",
              "      <th>the teacher</th>\n",
              "      <th>the world</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "      <th>york is</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   &  & roll  actor  actor in  ...  the world  world  york  york is\n",
              "0  1       1      0         0  ...          0      0     0        0\n",
              "1  0       0      1         1  ...          1      1     0        0\n",
              "2  0       0      0         0  ...          0      0     1        1\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alPhQeXaie-C"
      },
      "source": [
        "De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtenci贸n de frecuencias son los bigramas, que b谩sicamente son el conjunto de palabras de tama帽o de aparecen juntas en el texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ9_vzb0ie-C"
      },
      "source": [
        "## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtenci贸n de caracteristicas de la siguiente forma en un pipeline:\n",
        "\n",
        "- Utilice el tokenizador entregado.\n",
        "- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n",
        "\n",
        "```python\n",
        "bog = CountVectorizer(tokenizer= StemmerTokenizer(),`\n",
        "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
        "                      )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZy8XAD9ie-D"
      },
      "source": [
        "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
        "\n",
        "```python\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "```\n",
        "\n",
        "No es necesario que obtenga un dataframe en concreto con las caracter铆sticas solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
        "\n",
        "**To-Do:**\n",
        "- [ ] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
        "- [ ] Aplicar MinMaxScaler sobre los atributos de interes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQLUvRJYie-D"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBl_v6atZmWU"
      },
      "source": [
        "Transformamos la columna alignment en 1 y 0 , siendo 1 cuando corresponde a un super villano y 0 cuando no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzn_N0jP0xis"
      },
      "source": [
        "df_comics['alignment']=df_comics['alignment'].replace(\"Bad\", 1)\n",
        "df_comics['alignment']=df_comics['alignment'].replace(\"Good\", 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay080DunHcOS"
      },
      "source": [
        "#### C贸digo aqu铆 ####\n",
        "bog = CountVectorizer(tokenizer= StemmerTokenizer(),\n",
        "                      ngram_range=(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt8Ufto8LNWE"
      },
      "source": [
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agWr3exhMxNr"
      },
      "source": [
        "processing = ColumnTransformer(\n",
        "   transformers=[\n",
        "       ('bag_of_words',bog ,('history_text')),\n",
        "       ('minmax_scaler',MinMaxScaler(), atributos_de_interes),\n",
        "   ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHncQ-A-j4I"
      },
      "source": [
        "## 1.2 Dise帽o de Baseline y  Primer Entrenamiento  [1 Puntos]\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeMiptpQ_EWb"
      },
      "source": [
        "Genere un Pipeline con las caracteristicas solicitadas en la secci贸n 1.1, un selector de mejores features `SelectPercentile` con m茅trica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n",
        "\n",
        "Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estar谩 dado por el atributo `alignment`. \n",
        "\n",
        "Finalmente entrene el modelo y reporte el desempe帽o con un `classification_report`. 驴 Nos recomendar铆a predecir la alineaci贸n de BatCow con este clasificador?.\n",
        "\n",
        "**To-DO:**\n",
        "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1 y aplicar un clasificador  `MultinomialNB()`.\n",
        "- [ ] Entrenar el pipeline y comentar los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WaUTyhzie-E"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQWqotkM5Lq"
      },
      "source": [
        "pipe_1= Pipeline([('preprocessing',processing),\n",
        "                  ('percentil',SelectPercentile(f_classif,\n",
        "                                                      percentile=90)),\n",
        "                        ('clf',MultinomialNB())\n",
        "                        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08fIthnFNCwd"
      },
      "source": [
        "X = df_comics.drop(columns=[\"alignment\"])\n",
        "y = df_comics.loc[:, \"alignment\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60E3gblFNOfa"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   X, y, test_size=0.33, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz8CbU4-NWJw",
        "outputId": "b3993c32-c9dd-4a96-a430-c5800fa35731"
      },
      "source": [
        "y_sh_train=pipe_1.fit(X_train, y_train)\n",
        "y_sh_predict = pipe_1.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_sh_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.98      0.77       244\n",
            "           1       0.50      0.03      0.05       143\n",
            "\n",
            "    accuracy                           0.63       387\n",
            "   macro avg       0.57      0.51      0.41       387\n",
            "weighted avg       0.58      0.63      0.51       387\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm7I2B7_rfB"
      },
      "source": [
        "## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14siiavzK67p"
      },
      "source": [
        "No conformes con el rendimiento obtenido en la secci贸n 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes par谩metros para mejorar el rendimiento de la clasificaci贸n. Para esto, se le solicita que defina:\n",
        "\n",
        "- Dos clasificadores distintos en donde varie sus par谩metros. Se le recomienda utilizar `LogisticRegression()` y `RandomForestClassifier()`.\n",
        "- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. \n",
        "- Selecci贸n de las mejores columnas para la clasificaci贸n con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la m茅trica que usted quiera).\n",
        "\n",
        "A continuaci贸n, un ejemplo de parametros para GridSearch para una b煤squeda de 3 clasificadores distintos:\n",
        "\n",
        "```python\n",
        "params = [\n",
        "       # clasificador 1 + hiperpar谩metros\n",
        "       {'clf': classificator1(),\n",
        "        'clf__penalty': ['ovr'],\n",
        "        'clf__multi_class': ['liblinear']},\n",
        "       # clasificador 1 + hiperpar谩metros    \n",
        "       {'clf': classificator2(),\n",
        "        'clf__n_estimators': [200]},\n",
        "       # clasificador 1 + hiperpar谩metros\n",
        "       {'clf': classificator3(),\n",
        "        ...\n",
        "       }\n",
        "       ]\n",
        "```\n",
        "\n",
        "**Nota 1**: Puede ver los par谩metros modificables aplicando el m茅todo get_params() sobre su pipeline.\n",
        "\n",
        "**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n",
        "\n",
        "**Nota 3**: Puede usar en `HalvingGridSearchCV` el par谩metro `verbose=10` para ver que GridSearch le indique el estado de su ejecuci贸n.\n",
        "\n",
        "**Nota 3:** El GridSearch puede tomar tiempos de b煤squeda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de b煤squeda, dejar corriendo el c贸digo y tomarse un tecito."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUu74W9Wie-E"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNvHOHELUoIv"
      },
      "source": [
        "#### C贸digo aqu铆 ####\n",
        "pipe_2 = Pipeline(steps=[\n",
        "                         ('preprocessing',processing),\n",
        "                         ('percentil',SelectPercentile(f_classif,\n",
        "                                                      percentile=90)),\n",
        "                         (\"clf_lr\", LogisticRegression())\n",
        "                \n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1kxwDcifK7z",
        "outputId": "c8a8df9c-cde9-4c36-f17a-350b009830e5"
      },
      "source": [
        "y_sh_train2=pipe_2.fit(X_train, y_train)\n",
        "y_sh_predict2 = pipe_2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1UPMaaJfu_H",
        "outputId": "bbe9d9f2-4897-4d52-b2b3-ee192e45a316"
      },
      "source": [
        "print(classification_report(y_test, y_sh_predict2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.86      0.80       244\n",
            "           1       0.67      0.50      0.58       143\n",
            "\n",
            "    accuracy                           0.73       387\n",
            "   macro avg       0.71      0.68      0.69       387\n",
            "weighted avg       0.72      0.73      0.72       387\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zaILOrCfzr6"
      },
      "source": [
        "pipe_3 = Pipeline(steps=[\n",
        "                         ('preprocessing',processing),\n",
        "                         ('percentil',SelectPercentile(f_classif,\n",
        "                                                      percentile=90)),\n",
        "                         (\"clf_rf\", RandomForestClassifier())\n",
        "                \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kenYITEfgk_x"
      },
      "source": [
        "y_sh_train3=pipe_3.fit(X_train, y_train)\n",
        "y_sh_predict3 = pipe_3.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD5PgCIjg2rW",
        "outputId": "c6279364-85cd-4c8c-ce0d-db2dbc6f72f4"
      },
      "source": [
        "print(classification_report(y_test, y_sh_predict3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      1.00      0.78       244\n",
            "           1       0.86      0.04      0.08       143\n",
            "\n",
            "    accuracy                           0.64       387\n",
            "   macro avg       0.75      0.52      0.43       387\n",
            "weighted avg       0.72      0.64      0.52       387\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usIL5p8lQa_U"
      },
      "source": [
        "p_grid = [{\n",
        "    \"ngram\" : [(1,1), (1,2), (1,3)],\n",
        "    \"percentile\" : [20, 40, 60, 80],\n",
        "    \"score\" : [f_classif, mutual_info_classif],\n",
        "    \"clf_lr\" : [LogisticRegression(random_state=100)],\n",
        "    'clf_lr__penalty': ['ovr'],\n",
        "    'clf_lr__multi_class': ['liblinear']\n",
        "   \n",
        "}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo5Lh0XbYN_L"
      },
      "source": [
        "from sklearn.experimental import enable_halving_search_cv # noqa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uheOXWdJYSTl"
      },
      "source": [
        "from sklearn.model_selection import HalvingGridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ptqiB6yS3sY"
      },
      "source": [
        "grid_param = HalvingGridSearchCV(pipe_2, p_grid, verbose=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-GEHk0xi4z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af52103-3760-4f00-be69-9f40e4b23641"
      },
      "source": [
        "grid_param.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aggressive_elimination': False,\n",
              " 'cv': 5,\n",
              " 'error_score': nan,\n",
              " 'estimator': Pipeline(steps=[('preprocessing',\n",
              "                  ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                                   CountVectorizer(ngram_range=(1,\n",
              "                                                                                2),\n",
              "                                                                   tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                                   'history_text'),\n",
              "                                                  ('minmax_scaler',\n",
              "                                                   MinMaxScaler(),\n",
              "                                                   ['intelligence_score',\n",
              "                                                    'strength_score',\n",
              "                                                    'speed_score',\n",
              "                                                    'durability_score',\n",
              "                                                    'power_score',\n",
              "                                                    'combat_score'])])),\n",
              "                 ('percentil', SelectPercentile(percentile=90)),\n",
              "                 ('clf_lr', LogisticRegression())]),\n",
              " 'estimator__clf_lr': LogisticRegression(),\n",
              " 'estimator__clf_lr__C': 1.0,\n",
              " 'estimator__clf_lr__class_weight': None,\n",
              " 'estimator__clf_lr__dual': False,\n",
              " 'estimator__clf_lr__fit_intercept': True,\n",
              " 'estimator__clf_lr__intercept_scaling': 1,\n",
              " 'estimator__clf_lr__l1_ratio': None,\n",
              " 'estimator__clf_lr__max_iter': 100,\n",
              " 'estimator__clf_lr__multi_class': 'auto',\n",
              " 'estimator__clf_lr__n_jobs': None,\n",
              " 'estimator__clf_lr__penalty': 'l2',\n",
              " 'estimator__clf_lr__random_state': None,\n",
              " 'estimator__clf_lr__solver': 'lbfgs',\n",
              " 'estimator__clf_lr__tol': 0.0001,\n",
              " 'estimator__clf_lr__verbose': 0,\n",
              " 'estimator__clf_lr__warm_start': False,\n",
              " 'estimator__memory': None,\n",
              " 'estimator__percentil': SelectPercentile(percentile=90),\n",
              " 'estimator__percentil__percentile': 90,\n",
              " 'estimator__percentil__score_func': <function sklearn.feature_selection._univariate_selection.f_classif>,\n",
              " 'estimator__preprocessing': ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                  CountVectorizer(ngram_range=(1, 2),\n",
              "                                                  tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                  'history_text'),\n",
              "                                 ('minmax_scaler', MinMaxScaler(),\n",
              "                                  ['intelligence_score', 'strength_score',\n",
              "                                   'speed_score', 'durability_score',\n",
              "                                   'power_score', 'combat_score'])]),\n",
              " 'estimator__preprocessing__bag_of_words': CountVectorizer(ngram_range=(1, 2),\n",
              "                 tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              " 'estimator__preprocessing__bag_of_words__analyzer': 'word',\n",
              " 'estimator__preprocessing__bag_of_words__binary': False,\n",
              " 'estimator__preprocessing__bag_of_words__decode_error': 'strict',\n",
              " 'estimator__preprocessing__bag_of_words__dtype': numpy.int64,\n",
              " 'estimator__preprocessing__bag_of_words__encoding': 'utf-8',\n",
              " 'estimator__preprocessing__bag_of_words__input': 'content',\n",
              " 'estimator__preprocessing__bag_of_words__lowercase': True,\n",
              " 'estimator__preprocessing__bag_of_words__max_df': 1.0,\n",
              " 'estimator__preprocessing__bag_of_words__max_features': None,\n",
              " 'estimator__preprocessing__bag_of_words__min_df': 1,\n",
              " 'estimator__preprocessing__bag_of_words__ngram_range': (1, 2),\n",
              " 'estimator__preprocessing__bag_of_words__preprocessor': None,\n",
              " 'estimator__preprocessing__bag_of_words__stop_words': None,\n",
              " 'estimator__preprocessing__bag_of_words__strip_accents': None,\n",
              " 'estimator__preprocessing__bag_of_words__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'estimator__preprocessing__bag_of_words__tokenizer': <__main__.StemmerTokenizer at 0x7efe608e0750>,\n",
              " 'estimator__preprocessing__bag_of_words__vocabulary': None,\n",
              " 'estimator__preprocessing__minmax_scaler': MinMaxScaler(),\n",
              " 'estimator__preprocessing__minmax_scaler__clip': False,\n",
              " 'estimator__preprocessing__minmax_scaler__copy': True,\n",
              " 'estimator__preprocessing__minmax_scaler__feature_range': (0, 1),\n",
              " 'estimator__preprocessing__n_jobs': None,\n",
              " 'estimator__preprocessing__remainder': 'drop',\n",
              " 'estimator__preprocessing__sparse_threshold': 0.3,\n",
              " 'estimator__preprocessing__transformer_weights': None,\n",
              " 'estimator__preprocessing__transformers': [('bag_of_words',\n",
              "   CountVectorizer(ngram_range=(1, 2),\n",
              "                   tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "   'history_text'),\n",
              "  ('minmax_scaler',\n",
              "   MinMaxScaler(),\n",
              "   ['intelligence_score',\n",
              "    'strength_score',\n",
              "    'speed_score',\n",
              "    'durability_score',\n",
              "    'power_score',\n",
              "    'combat_score'])],\n",
              " 'estimator__preprocessing__verbose': False,\n",
              " 'estimator__preprocessing__verbose_feature_names_out': True,\n",
              " 'estimator__steps': [('preprocessing',\n",
              "   ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                    CountVectorizer(ngram_range=(1, 2),\n",
              "                                                    tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                    'history_text'),\n",
              "                                   ('minmax_scaler', MinMaxScaler(),\n",
              "                                    ['intelligence_score', 'strength_score',\n",
              "                                     'speed_score', 'durability_score',\n",
              "                                     'power_score', 'combat_score'])])),\n",
              "  ('percentil', SelectPercentile(percentile=90)),\n",
              "  ('clf_lr', LogisticRegression())],\n",
              " 'estimator__verbose': False,\n",
              " 'factor': 3,\n",
              " 'max_resources': 'auto',\n",
              " 'min_resources': 'exhaust',\n",
              " 'n_jobs': None,\n",
              " 'param_grid': [{'clf_lr': [LogisticRegression(random_state=100)],\n",
              "   'clf_lr__multi_class': ['liblinear'],\n",
              "   'clf_lr__penalty': ['ovr'],\n",
              "   'ngram': [(1, 1), (1, 2), (1, 3)],\n",
              "   'percentile': [20, 40, 60, 80],\n",
              "   'score': [<function sklearn.feature_selection._univariate_selection.f_classif>,\n",
              "    <function sklearn.feature_selection._mutual_info.mutual_info_classif>]}],\n",
              " 'random_state': None,\n",
              " 'refit': True,\n",
              " 'resource': 'n_samples',\n",
              " 'return_train_score': True,\n",
              " 'scoring': None,\n",
              " 'verbose': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTmik1auhQwv"
      },
      "source": [
        "p_grid2 = [{\n",
        "    \"ngram\" : [(1,1), (1,2), (1,3)],\n",
        "    \"percentile\" : [20, 40, 60, 80],\n",
        "    \"score\" : [f_classif, mutual_info_classif],\n",
        "    \"clf_rf\" : [RandomForestClassifier(random_state=100)],\n",
        "    'clf__n_estimators': [200, 400, 600, 800, 1000, 2000]\n",
        "\n",
        "}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBJuhaB0hmQY"
      },
      "source": [
        "grid_param2 = HalvingGridSearchCV(pipe_3, p_grid2, verbose=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9UqKBz-l5pl",
        "outputId": "619ac5ba-e3fe-40af-a4bc-adf5f3d432f8"
      },
      "source": [
        "grid_param2.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aggressive_elimination': False,\n",
              " 'cv': 5,\n",
              " 'error_score': nan,\n",
              " 'estimator': Pipeline(steps=[('preprocessing',\n",
              "                  ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                                   CountVectorizer(ngram_range=(1,\n",
              "                                                                                2),\n",
              "                                                                   tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                                   'history_text'),\n",
              "                                                  ('minmax_scaler',\n",
              "                                                   MinMaxScaler(),\n",
              "                                                   ['intelligence_score',\n",
              "                                                    'strength_score',\n",
              "                                                    'speed_score',\n",
              "                                                    'durability_score',\n",
              "                                                    'power_score',\n",
              "                                                    'combat_score'])])),\n",
              "                 ('percentil', SelectPercentile(percentile=90)),\n",
              "                 ('clf_rf', RandomForestClassifier())]),\n",
              " 'estimator__clf_rf': RandomForestClassifier(),\n",
              " 'estimator__clf_rf__bootstrap': True,\n",
              " 'estimator__clf_rf__ccp_alpha': 0.0,\n",
              " 'estimator__clf_rf__class_weight': None,\n",
              " 'estimator__clf_rf__criterion': 'gini',\n",
              " 'estimator__clf_rf__max_depth': None,\n",
              " 'estimator__clf_rf__max_features': 'auto',\n",
              " 'estimator__clf_rf__max_leaf_nodes': None,\n",
              " 'estimator__clf_rf__max_samples': None,\n",
              " 'estimator__clf_rf__min_impurity_decrease': 0.0,\n",
              " 'estimator__clf_rf__min_samples_leaf': 1,\n",
              " 'estimator__clf_rf__min_samples_split': 2,\n",
              " 'estimator__clf_rf__min_weight_fraction_leaf': 0.0,\n",
              " 'estimator__clf_rf__n_estimators': 100,\n",
              " 'estimator__clf_rf__n_jobs': None,\n",
              " 'estimator__clf_rf__oob_score': False,\n",
              " 'estimator__clf_rf__random_state': None,\n",
              " 'estimator__clf_rf__verbose': 0,\n",
              " 'estimator__clf_rf__warm_start': False,\n",
              " 'estimator__memory': None,\n",
              " 'estimator__percentil': SelectPercentile(percentile=90),\n",
              " 'estimator__percentil__percentile': 90,\n",
              " 'estimator__percentil__score_func': <function sklearn.feature_selection._univariate_selection.f_classif>,\n",
              " 'estimator__preprocessing': ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                  CountVectorizer(ngram_range=(1, 2),\n",
              "                                                  tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                  'history_text'),\n",
              "                                 ('minmax_scaler', MinMaxScaler(),\n",
              "                                  ['intelligence_score', 'strength_score',\n",
              "                                   'speed_score', 'durability_score',\n",
              "                                   'power_score', 'combat_score'])]),\n",
              " 'estimator__preprocessing__bag_of_words': CountVectorizer(ngram_range=(1, 2),\n",
              "                 tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              " 'estimator__preprocessing__bag_of_words__analyzer': 'word',\n",
              " 'estimator__preprocessing__bag_of_words__binary': False,\n",
              " 'estimator__preprocessing__bag_of_words__decode_error': 'strict',\n",
              " 'estimator__preprocessing__bag_of_words__dtype': numpy.int64,\n",
              " 'estimator__preprocessing__bag_of_words__encoding': 'utf-8',\n",
              " 'estimator__preprocessing__bag_of_words__input': 'content',\n",
              " 'estimator__preprocessing__bag_of_words__lowercase': True,\n",
              " 'estimator__preprocessing__bag_of_words__max_df': 1.0,\n",
              " 'estimator__preprocessing__bag_of_words__max_features': None,\n",
              " 'estimator__preprocessing__bag_of_words__min_df': 1,\n",
              " 'estimator__preprocessing__bag_of_words__ngram_range': (1, 2),\n",
              " 'estimator__preprocessing__bag_of_words__preprocessor': None,\n",
              " 'estimator__preprocessing__bag_of_words__stop_words': None,\n",
              " 'estimator__preprocessing__bag_of_words__strip_accents': None,\n",
              " 'estimator__preprocessing__bag_of_words__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'estimator__preprocessing__bag_of_words__tokenizer': <__main__.StemmerTokenizer at 0x7efe608e0750>,\n",
              " 'estimator__preprocessing__bag_of_words__vocabulary': None,\n",
              " 'estimator__preprocessing__minmax_scaler': MinMaxScaler(),\n",
              " 'estimator__preprocessing__minmax_scaler__clip': False,\n",
              " 'estimator__preprocessing__minmax_scaler__copy': True,\n",
              " 'estimator__preprocessing__minmax_scaler__feature_range': (0, 1),\n",
              " 'estimator__preprocessing__n_jobs': None,\n",
              " 'estimator__preprocessing__remainder': 'drop',\n",
              " 'estimator__preprocessing__sparse_threshold': 0.3,\n",
              " 'estimator__preprocessing__transformer_weights': None,\n",
              " 'estimator__preprocessing__transformers': [('bag_of_words',\n",
              "   CountVectorizer(ngram_range=(1, 2),\n",
              "                   tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "   'history_text'),\n",
              "  ('minmax_scaler',\n",
              "   MinMaxScaler(),\n",
              "   ['intelligence_score',\n",
              "    'strength_score',\n",
              "    'speed_score',\n",
              "    'durability_score',\n",
              "    'power_score',\n",
              "    'combat_score'])],\n",
              " 'estimator__preprocessing__verbose': False,\n",
              " 'estimator__preprocessing__verbose_feature_names_out': True,\n",
              " 'estimator__steps': [('preprocessing',\n",
              "   ColumnTransformer(transformers=[('bag_of_words',\n",
              "                                    CountVectorizer(ngram_range=(1, 2),\n",
              "                                                    tokenizer=<__main__.StemmerTokenizer object at 0x7efe608e0750>),\n",
              "                                    'history_text'),\n",
              "                                   ('minmax_scaler', MinMaxScaler(),\n",
              "                                    ['intelligence_score', 'strength_score',\n",
              "                                     'speed_score', 'durability_score',\n",
              "                                     'power_score', 'combat_score'])])),\n",
              "  ('percentil', SelectPercentile(percentile=90)),\n",
              "  ('clf_rf', RandomForestClassifier())],\n",
              " 'estimator__verbose': False,\n",
              " 'factor': 3,\n",
              " 'max_resources': 'auto',\n",
              " 'min_resources': 'exhaust',\n",
              " 'n_jobs': None,\n",
              " 'param_grid': [{'clf__n_estimators': [200, 400, 600, 800, 1000, 2000],\n",
              "   'clf_rf': [RandomForestClassifier(random_state=100)],\n",
              "   'ngram': [(1, 1), (1, 2), (1, 3)],\n",
              "   'percentile': [20, 40, 60, 80],\n",
              "   'score': [<function sklearn.feature_selection._univariate_selection.f_classif>,\n",
              "    <function sklearn.feature_selection._mutual_info.mutual_info_classif>]}],\n",
              " 'random_state': None,\n",
              " 'refit': True,\n",
              " 'resource': 'n_samples',\n",
              " 'return_train_score': True,\n",
              " 'scoring': None,\n",
              " 'verbose': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQUw2aZ_6z2"
      },
      "source": [
        "## 1.4 Predicci贸n del datos sin etiquetado  [0.5 puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj0ERBgTBFWN"
      },
      "source": [
        "LLego el momento de predecir \n",
        "`Vergil`, `Gorilla Girl` y `Batcow`\n",
        "\n",
        "\n",
        "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXecOsI8ie-F"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLdROpizie-F"
      },
      "source": [
        "#### C贸digo aqu铆 ####\n",
        "df_comics_no_label = pd.read_csv('/content/drive/MyDrive/LaboratorioDS/Lab8/comics_no_label.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZfflQRlny8U",
        "outputId": "e9d2b401-8a0a-4812-bf0a-61f63a67c76f"
      },
      "source": [
        "df_comics_no_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ASfEdbNn30f",
        "outputId": "3f66d6d6-9197-4c2e-b201-9ce79398f64b"
      },
      "source": [
        "df_comics_no_label[\"history_text\"].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFio-MM1myFR"
      },
      "source": [
        "df_comics_no_label = df_comics_no_label.drop(df_comics_no_label[pd.isna(df_comics_no_label[\"history_text\"])== True].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq2vZo9soNTR",
        "outputId": "a6fd1ad6-98c7-4280-cb28-04962108372e"
      },
      "source": [
        "df_comics_no_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T3qry5ZoQ58"
      },
      "source": [
        "predictions = pipe_1.predict(df_comics_no_label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vth57TGipNGr",
        "outputId": "69294d2a-265b-4acb-deff-6023222b20dd"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jISAaK-v8ck"
      },
      "source": [
        "d = np.array(df_comics_no_label[\"name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCZrjKxEjjyJ"
      },
      "source": [
        "Probamos con el clasificdor Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWUTQTBfrWgq"
      },
      "source": [
        "df_a = pd.DataFrame({\"Nombre\": d, \"Villano?\": predictions})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDBLEwa0x_Kv",
        "outputId": "3dc6711f-8bad-43d0-ffae-57e8a44ffde2"
      },
      "source": [
        "df_a[\"Villano?\"].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O92Aacqow4_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "1fc010ca-3697-4a81-dddb-82565eac1241"
      },
      "source": [
        "df_b = df_a.loc[df_a['Nombre'] == \"Batcow\"]\n",
        "df_b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Nombre  Villano?\n",
              "14  Batcow         0\n",
              "75  Batcow         0"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G-ODFZcxVd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "1ff07293-6f6f-4674-c579-8260203e8324"
      },
      "source": [
        "df_c = df_a.loc[df_a[\"Nombre\"] == \"Vergil\"]\n",
        "df_c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Vergil</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Nombre  Villano?\n",
              "71  Vergil         0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjEbiURx1Cw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "4f1acc0e-20e7-4c6b-be50-a4918e74a712"
      },
      "source": [
        "df_d = df_a.loc[df_a[\"Nombre\"] == \"Gorilla Girl\"]\n",
        "df_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Nombre  Villano?\n",
              "37  Gorilla Girl         0"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF_pC03hratE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "0fda0a62-3210-4676-ccf6-2d74fd40687a"
      },
      "source": [
        "df_e = df_a.loc[df_a[\"Villano?\"] == 1]\n",
        "df_e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Bruce Banner (Wild West)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Destroyer (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Kurse (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Proxima Midnight</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Scorpion (injustice)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>The Rhino (SONY)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Nombre  Villano?\n",
              "20  Bruce Banner (Wild West)         1\n",
              "29           Destroyer (MCU)         1\n",
              "48               Kurse (MCU)         1\n",
              "54          Proxima Midnight         1\n",
              "61      Scorpion (injustice)         1\n",
              "67          The Rhino (SONY)         1"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEDFdhkhg6K5"
      },
      "source": [
        "Segundo modelo con clasificador de regresi贸n logistica y el con mejor desempe帽o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oq-uph7g8JG"
      },
      "source": [
        "predictions2 = pipe_2.predict(df_comics_no_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo73eflslMr9",
        "outputId": "d8bb5e3d-5ca7-4948-e0ed-b3441c5e584b"
      },
      "source": [
        "predictions2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siBcQy_ThCmm"
      },
      "source": [
        "df_a2 = pd.DataFrame({\"Nombre\": d, \"Villano?\": predictions2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_WPc7fUig6l",
        "outputId": "e21ae4b3-9571-4e3d-bd4e-7f5965d60ccf"
      },
      "source": [
        "df_a2[\"Villano?\"].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4649g3lRhgfi",
        "outputId": "89e97697-5be6-477f-b7cb-5259cd48de45"
      },
      "source": [
        "df_b2 = df_a2.loc[df_a2['Nombre'] == \"Batcow\"]\n",
        "df_b2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Nombre  Villano?\n",
              "14  Batcow         1\n",
              "75  Batcow         1"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "CF8FfQ1kiqHo",
        "outputId": "6f47ea82-c1db-4027-d7de-ceb6b981fbac"
      },
      "source": [
        "df_c2 = df_a2.loc[df_a2[\"Nombre\"] == \"Vergil\"]\n",
        "df_c2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Vergil</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Nombre  Villano?\n",
              "71  Vergil         0"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "TitgzOdEiu9P",
        "outputId": "93feed65-7552-4365-a5c1-ad9e46c68556"
      },
      "source": [
        "df_d2 = df_a2.loc[df_a2[\"Nombre\"] == \"Gorilla Girl\"]\n",
        "df_d2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Nombre  Villano?\n",
              "37  Gorilla Girl         0"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "FIfHHpM8i2e2",
        "outputId": "1b64d721-109d-4506-dadc-e1cc208cffa9"
      },
      "source": [
        "df_e2 = df_a2.loc[df_a2[\"Villano?\"] == 1]\n",
        "df_e2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A'dal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A.M.A.Z.O. (CW)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ancalagon</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Anti-Venom</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Arizona Annie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Black Panther (1,000,000 B.C.)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Blackwulf</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Dark Elf Soldier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Destroyer (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fenris (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>J. Jonah Jameson</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Jestro</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Joker (Gotham)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Karnak</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Kurse (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Magneto (FOX)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Red Tornado (CW)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Ronan The Accuser (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Scorpion (injustice)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Starro The Star Conqueror</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>The Rhino (SONY)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Thinker</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Wendigo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Yondu (MCU)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Nombre  Villano?\n",
              "1                            A'dal         1\n",
              "4                  A.M.A.Z.O. (CW)         1\n",
              "5                        Ancalagon         1\n",
              "6                       Anti-Venom         1\n",
              "10                   Arizona Annie         1\n",
              "14                          Batcow         1\n",
              "18  Black Panther (1,000,000 B.C.)         1\n",
              "19                       Blackwulf         1\n",
              "23                             NaN         1\n",
              "27                Dark Elf Soldier         1\n",
              "29                 Destroyer (MCU)         1\n",
              "33                    Fenris (MCU)         1\n",
              "43                J. Jonah Jameson         1\n",
              "44                          Jestro         1\n",
              "45                  Joker (Gotham)         1\n",
              "46                          Karnak         1\n",
              "48                     Kurse (MCU)         1\n",
              "51                   Magneto (FOX)         1\n",
              "56                Red Tornado (CW)         1\n",
              "60         Ronan The Accuser (MCU)         1\n",
              "61            Scorpion (injustice)         1\n",
              "62       Starro The Star Conqueror         1\n",
              "67                The Rhino (SONY)         1\n",
              "68                         Thinker         1\n",
              "72                         Wendigo         1\n",
              "74                     Yondu (MCU)         1\n",
              "75                          Batcow         1"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB53wapxjGo2"
      },
      "source": [
        "Tercer modelo con random forest, el peor modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZkyh4UsjGN0"
      },
      "source": [
        "predictions3 = pipe_3.predict(df_comics_no_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8dODp9rlVjE",
        "outputId": "1dec44da-cfc2-4880-a95f-dc5197e39455"
      },
      "source": [
        "predictions3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTGo0wbhjNlW"
      },
      "source": [
        "df_a3 = pd.DataFrame({\"Nombre\": d, \"Villano?\": predictions3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl--yQztjSW1",
        "outputId": "6be4ae8f-40da-4ee3-e5b7-2f8615a16dcd"
      },
      "source": [
        "df_a3[\"Villano?\"].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "3-ZGaL3vj04m",
        "outputId": "9728dbee-4e5b-46ae-b7cc-79db63c860c4"
      },
      "source": [
        "df_e3 = df_a3.loc[df_a3[\"Villano?\"] == 1]\n",
        "df_e3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Villano?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Nombre, Villano?]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg4ZMq8ezAH6"
      },
      "source": [
        "# Conclusi贸n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los d铆as de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6N75ZlKie-G"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ]
}